{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lovrorabuzin/swiftnet-zavrad?scriptVersionId=91692088\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Importi i hiperparametri","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.nn import functional\nimport torch.nn.functional as F\n\nimport sklearn\nfrom sklearn import model_selection\n\nimport torchvision\nimport torchvision.transforms as torch_transforms\nimport torch.utils.data as data\nimport torch.optim as optim\nimport torchvision.models as models\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import random_split\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import Subset\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\n\nimport pickle\nimport numpy as np\nimport math\nimport pandas as pd\n\nimport skimage as ski\nimport skimage.io\nimport os\n\nimport random\n\nimport nibabel as nib\nfrom PIL import Image\nimport imageio\n\nimport torch.utils.checkpoint as cp\n\nimport sys\nimport json\n\nfrom math import e\n\nb_s = 1\nlearning_rate = 0.0001\nscaling_factor = 2\nweight_decay = 0.0005\ngamma = 0.95\nnum_epochs = 30\nslice_no = 200\nrandom.seed()\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nroot_train_dir = '../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'","metadata":{"execution":{"iopub.status.busy":"2021-06-10T21:31:23.052494Z","iopub.execute_input":"2021-06-10T21:31:23.052809Z","iopub.status.idle":"2021-06-10T21:31:23.12492Z","shell.execute_reply.started":"2021-06-10T21:31:23.05278Z","shell.execute_reply":"2021-06-10T21:31:23.124074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Učitavanje podataka","metadata":{}},{"cell_type":"code","source":"name_mapping = pd.read_csv(root_train_dir + '/name_mapping.csv')\n\nname_mapping.rename({'BraTS_2020_subject_ID': 'ID'}, axis=1, inplace=True)\n\nsurvival_info = pd.read_csv(root_train_dir + '/survival_info.csv')\n\nsurvival_info.rename({'Brats20ID': 'ID'}, axis=1, inplace=True)\n\npatient_info = survival_info.merge(name_mapping, on=\"ID\", how=\"right\")\n\nmodalities = ['_flair.nii', '_t1.nii', '_t1ce.nii', '_t2.nii']\nmask_path = '_seg.nii'\n\ntrain_scan_files = []\nvalid_scan_files = []\ntest_scan_files = []\n\nHGG_names = list(patient_info[patient_info['Grade'] == 'HGG'].ID)\nLGG_names = list(patient_info[patient_info['Grade'] == 'LGG'].ID)\n\nfor i in range(len(HGG_names)):\n    image_path = root_train_dir+'/'+HGG_names[i]+'/'+HGG_names[i]\n    if i % 7 == 5:\n        valid_scan_files.append(image_path)\n    elif i % 7 == 4:\n        test_scan_files.append(image_path)\n    else:\n        train_scan_files.append(image_path)\n\nfor i in range(len(LGG_names)):\n    image_path = root_train_dir+'/'+LGG_names[i]+'/'+LGG_names[i]\n    if i % 7 == 5:\n        valid_scan_files.append(image_path)\n    elif i % 7 == 4:\n        test_scan_files.append(image_path)\n    else:\n        train_scan_files.append(image_path)\n\nhorizontalFlipTransform = torch_transforms.RandomHorizontalFlip(p = 0.5)\ntoTensor = torch_transforms.ToTensor()\n\ntrainTransform = torch_transforms.Compose([toTensor, horizontalFlipTransform])\n\ndef normalize_vol(volume, i):\n    logical_mask = volume != 0.\n    mean = np.mean(volume[logical_mask])\n    std = np.std(volume[logical_mask])\n    return (volume-mean)/std\n\nclass SegmentationDataset(Dataset):\n    in_channels = 4\n    out_channels = 4\n    \n    def __init__(self, paths, modalities, mask_path, tumor_slices, slice_no = 155, transform = None):\n        self.paths = paths\n        self.modalities = modalities\n        self.mask_path = mask_path\n        self.transform = transform\n        self.mask_buffer = np.array([])\n        self.volume_buffer = np.array([])\n        self.passes = 0\n        self.tumor_slices = tumor_slices\n        random.shuffle(self.paths)\n        \n    def __len__(self):\n        return math.ceil(self.tumor_slices/slice_no)\n    \n    def reset(self):\n        self.passes = 0\n        random.shuffle(self.paths)\n    \n    def __getitem__(self, idx):\n        if self.mask_buffer.size > 0:\n            bound = min(slice_no, self.mask_buffer.shape[0])\n            res_mask = self.mask_buffer[:bound]\n            res_volume = self.volume_buffer[:bound]\n            if bound < self.mask_buffer.shape[0]:\n                self.mask_buffer = self.mask_buffer[bound:]\n                self.volume_buffer = self.volume_buffer[bound:]\n            else:\n                self.mask_buffer = np.array([])\n                self.volume_buffer = np.array([])\n        else:\n            res_mask = np.array([])\n            res_volume = np.array([])\n        \n        while res_mask.shape[0] < slice_no and idx + self.passes < len(self.paths):\n            patient = self.paths[idx+self.passes]\n            self.passes += 1\n            volumes = []\n            single_mask = patient + mask_path\n            if single_mask == root_train_dir + '/BraTS20_Training_355/BraTS20_Training_355_seg.nii':\n                single_mask = root_train_dir + '/BraTS20_Training_355/W39_1998.09.19_Segm.nii'\n            single_mask = nib.load(single_mask)\n            single_mask = np.asarray(single_mask.dataobj, dtype = np.float)\n            mask = single_mask.transpose(2,0,1)\n            mask_WT = mask.copy()\n            mask_WT[mask_WT == 1] = 0\n            mask_WT[mask_WT == 2] = 1\n            mask_WT[mask_WT == 4] = 0\n\n            mask_TC = mask.copy()\n            mask_TC[mask_TC == 1] = 1\n            mask_TC[mask_TC == 2] = 0\n            mask_TC[mask_TC == 4] = 0\n\n            mask_ET = mask.copy()\n            mask_ET[mask_ET == 1] = 0\n            mask_ET[mask_ET == 2] = 0\n            mask_ET[mask_ET == 4] = 1\n\n            mask_BG = mask.copy()\n            mask_BG[mask_BG == 0] = 3\n            mask_BG[mask_BG == 1] = 0\n            mask_BG[mask_BG == 2] = 0\n            mask_BG[mask_BG == 4] = 0\n            mask_BG[mask_BG == 3] = 1\n\n            mask_full = np.stack([mask_WT, mask_TC, mask_ET, mask_BG])\n            mask_full = np.transpose(mask_full, (1,0,2,3))\n\n            tumor_indices = []\n            mask_pure = []\n            for i in range(155):\n                mask_slice = mask_full[i]\n                if np.sum(mask_slice[0:3]) != 0:\n                    tumor_indices.append(i)\n                    mask_pure.append(mask_slice)\n            mask = np.stack(mask_pure)\n\n            for modality in modalities:\n                single_mod_volume = patient + modality\n                single_mod_volume = nib.load(single_mod_volume)\n                single_mod_volume = np.asarray(single_mod_volume.dataobj, dtype = np.float)\n                single_mod_volume = single_mod_volume.transpose(2,0,1)\n                intermittent = []\n                for i_s in tumor_indices:\n                    intermittent.append(single_mod_volume[i_s])\n                volumes.append(np.stack(intermittent))\n\n            if self.transform:\n                seed = random.randint(0,2**32)\n                random.seed(seed)\n                torch.manual_seed(seed)\n                volumes = np.transpose(np.stack(volumes), (1,0,2,3))\n                volumes = np.stack([self.transform(np.transpose(volumes[i], (1,2,0))) for i in range(np.shape(volumes)[0])])\n                volumes = np.transpose(np.stack(volumes), (1,0,2,3))\n                random.seed(seed)\n                torch.manual_seed(seed)\n                mask = np.stack([self.transform(np.transpose(mask[i], (1,2,0))) for i in range(np.shape(mask)[0])])\n            volumes = [normalize_vol(volumes[i], i) for i in range(np.shape(volumes)[0])]\n            volumes = np.transpose(np.stack(volumes), (1,0,2,3))\n            bound = min(slice_no-res_mask.shape[0], mask.shape[0])\n            if res_mask.size == 0:\n                res_mask = mask[:bound]\n                res_volume = volumes[:bound]\n            else:\n                res_mask = np.concatenate((res_mask, mask[:bound]), axis = 0)\n                res_volume = np.concatenate((res_volume, volumes[:bound]), axis = 0)\n            if bound < mask.shape[0]:\n                if self.mask_buffer.size == 0:\n                    self.mask_buffer = mask[bound:]\n                    self.volume_buffer = volumes[bound:]\n                else:\n                    self.mask_buffer = np.concatenate((self.mask_buffer, mask[bound:]), axis = 0)\n                    self.volume_buffer = np.concatenate((self.volume_buffer, volumes[bound:]), axis = 0)\n        self.passes -= 1\n        res_volume = torch.from_numpy(res_volume).float()\n        res_mask = torch.from_numpy(res_mask).long()\n        return res_volume, res_mask\n    \nclass TestingDataset(Dataset):\n    in_channels = 4\n    out_channels = 4\n    \n    def __init__(self, paths, modalities, mask_path):\n        self.paths = paths\n        self.modalities = modalities\n        self.mask_path = mask_path\n        self.mask_buffer = np.array([])\n        self.volume_buffer = np.array([])\n        \n        \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, idx):\n        patient = self.paths[idx]\n        volumes = []\n        single_mask = patient + mask_path\n        if single_mask == root_train_dir + '/BraTS20_Training_355/BraTS20_Training_355_seg.nii':\n            single_mask = root_train_dir + '/BraTS20_Training_355/W39_1998.09.19_Segm.nii'\n        single_mask = nib.load(single_mask)\n        single_mask = np.asarray(single_mask.dataobj, dtype = np.float)\n        mask = single_mask.transpose(2,0,1)\n        mask_WT = mask.copy()\n        mask_WT[mask_WT == 1] = 0\n        mask_WT[mask_WT == 2] = 1\n        mask_WT[mask_WT == 4] = 0\n\n        mask_TC = mask.copy()\n        mask_TC[mask_TC == 1] = 1\n        mask_TC[mask_TC == 2] = 0\n        mask_TC[mask_TC == 4] = 0\n\n        mask_ET = mask.copy()\n        mask_ET[mask_ET == 1] = 0\n        mask_ET[mask_ET == 2] = 0\n        mask_ET[mask_ET == 4] = 1\n\n        mask_BG = mask.copy()\n        mask_BG[mask_BG == 0] = 3\n        mask_BG[mask_BG == 1] = 0\n        mask_BG[mask_BG == 2] = 0\n        mask_BG[mask_BG == 4] = 0\n        mask_BG[mask_BG == 3] = 1\n        mask_full = np.stack([mask_WT, mask_TC, mask_ET, mask_BG])#, mask_BG\n        mask_full = np.transpose(mask_full, (1,0,2,3))\n        \n        for modality in modalities:\n                single_mod_volume = patient + modality\n                single_mod_volume = nib.load(single_mod_volume)\n                single_mod_volume = np.asarray(single_mod_volume.dataobj, dtype = np.float)\n                single_mod_volume = single_mod_volume.transpose(2,0,1)\n                volumes.append(np.stack(single_mod_volume))\n\n        volumes = [normalize_vol(volumes[i], i) for i in range(np.shape(volumes)[0])]\n        volumes = np.transpose(np.stack(volumes), (1,0,2,3))\n        res_volume = torch.from_numpy(volumes).float()\n        res_mask = torch.from_numpy(mask_full).long()\n\n        return res_volume, res_mask\n\n\n\ntrainset = SegmentationDataset(train_scan_files, modalities, mask_path, 17227, transform = trainTransform)\nvalidset = SegmentationDataset(valid_scan_files, modalities, mask_path, 3661)\ntestset = TestingDataset(test_scan_files, modalities, mask_path)\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=b_s, shuffle=False, num_workers=0)\nvalidloader = torch.utils.data.DataLoader(validset, batch_size=b_s,shuffle=False, num_workers=0)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=b_s, shuffle=False, num_workers=0)","metadata":{"papermill":{"duration":0.178986,"end_time":"2021-06-04T11:06:48.687676","exception":false,"start_time":"2021-06-04T11:06:48.50869","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-10T21:31:23.197954Z","iopub.execute_input":"2021-06-10T21:31:23.198213Z","iopub.status.idle":"2021-06-10T21:31:23.261304Z","shell.execute_reply.started":"2021-06-10T21:31:23.198187Z","shell.execute_reply":"2021-06-10T21:31:23.260554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neuronska mreža (SwiftNet)","metadata":{}},{"cell_type":"code","source":"upsample = lambda x, size: F.interpolate(x, size, mode='bilinear', align_corners=False)\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, in_channels, channels, stride=1, identity_downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size = 3, stride = stride, padding = 1, bias = False)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.relu = nn.ReLU()\n        self.conv2 = nn.Conv2d(channels, channels, kernel_size = 3, padding = 1, bias = False)\n        self.bn2 = nn.BatchNorm2d(channels)\n        self.downsample = identity_downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x.clone()\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        if self.downsample is not None:\n            residual = self.downsample(residual)\n        x += residual\n        relu = self.relu(x)\n        return relu, x\n\n\nclass BNReLUConv(nn.Sequential):\n    def __init__(self, in_channels, out_channels, k=3):\n        super(BNReLUConv, self).__init__()\n        self.add_module('BN', nn.BatchNorm2d(in_channels))\n        self.add_module('ReLU', nn.ReLU())\n        padding = k // 2\n        self.add_module('Conv', nn.Conv2d(in_channels, out_channels, k, padding=padding, bias=False))\n\n        \nclass Up(nn.Module):\n    def __init__(self, in_channels, skip_channels, out_channels, k=3):\n        super(Up, self).__init__()\n        self.bottleneck = BNReLUConv(skip_channels, in_channels, k = 1)\n        self.blend = BNReLUConv(in_channels, out_channels, k = k)\n        self.upsample = lambda x, size: F.interpolate(x, size, mode='bilinear', align_corners=False)\n    \n    def forward(self, x, skip):\n        skip = self.bottleneck.forward(skip)\n        skip_size = skip.size()[2:4]\n        x = self.upsample(x, skip_size)\n        x = x + skip\n        x = self.blend.forward(x)\n        return x\n\n\nclass SPP(nn.Module):\n    def __init__(self, in_channels, num_levels, bt_size, level_size, out_size, grids):\n        super(SPP, self).__init__()\n        self.upsample = lambda x, size: F.interpolate(x, size, mode='bilinear', align_corners=False)\n        self.spp = nn.Sequential()\n        self.spp.add_module('spp_bn', BNReLUConv(in_channels, bt_size, k=1))\n        self.grids = grids\n        num_features = bt_size\n        final_size = num_features\n        for i in range(num_levels):\n            final_size += level_size\n            self.spp.add_module('spp' + str(i), BNReLUConv(num_features, level_size, k=1))\n        self.spp.add_module('spp_fuse', BNReLUConv(final_size, out_size, k=1))\n        \n    def forward(self, x):\n        levels = []\n        target_size = x.size()[2:4]\n        x = self.spp[0].forward(x)\n        levels.append(x)\n        num = len(self.spp) - 1\n        for i in range(1, num):\n            x_pooled = F.adaptive_avg_pool2d(x, self.grids[i - 1])\n            level = self.spp[i].forward(x_pooled)\n            level = self.upsample(level, target_size)\n            levels.append(level)\n        x = torch.cat(levels, 1)\n        x = self.spp[-1].forward(x)\n        return x\n\n\nclass ResNet(nn.Module):\n    def __init__(self, residual_block, layers, image_channels=4):\n        super(ResNet, self).__init__()\n        self.inplanes = 64\n        self.num_features = 128\n        self.conv1 = nn.Conv2d(4, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        upsamples = []\n        self.layer1 = self._make_layer(residual_block, 64, layers[0])\n        upsamples += [Up(128, 64, 128)]\n        self.layer2 = self._make_layer(residual_block, 128, layers[1], stride=2)\n        upsamples += [Up(128, 128, 128)]\n        self.layer3 = self._make_layer(residual_block, 256, layers[2], stride=2)\n        upsamples += [Up(128, 256, 128)]\n        self.layer4 = self._make_layer(residual_block, 512, layers[3], stride=2)\n        \n        num_levels = 3\n        self.spp_size = 128\n        bt_size = self.spp_size\n        level_size = self.spp_size // num_levels\n        self.spp = SPP(self.inplanes, num_levels, bt_size=bt_size, level_size=level_size, out_size=128, grids = (8,4,2,1))\n        self.upsample = nn.ModuleList(list(reversed(upsamples)))\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward_resblock(self, x, layers):\n        skip = None\n        for l in layers:\n            x = l(x)\n            if isinstance(x, tuple):\n                x, skip = x\n        return x, skip\n\n    def forward_down(self, image):\n        x = self.conv1(image)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        features = []\n        x, skip = self.forward_resblock(x, self.layer1)\n        features += [skip]\n        x, skip = self.forward_resblock(x, self.layer2)\n        features += [skip]\n        x, skip = self.forward_resblock(x, self.layer3)\n        features += [skip]\n        x, skip = self.forward_resblock(x, self.layer4)\n        features += [self.spp.forward(skip)]\n        return features\n\n    def forward_up(self, features):\n        features = features[::-1]\n        x = features[0]\n        upsamples = []\n        for skip, up in zip(features[1:], self.upsample):\n            x = up(x, skip)\n            upsamples += [x]\n        return x, {'features': features, 'upsamples': upsamples}\n\n    def forward(self, image):\n        return self.forward_up(self.forward_down(image))\n    \n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            layers = [nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False)]\n            layers += [nn.BatchNorm2d(planes * block.expansion)]\n            downsample = nn.Sequential(*layers)\n        layers = [block(self.inplanes, planes, stride, downsample)]\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers += [block(self.inplanes, planes)]\n        return nn.Sequential(*layers)\n\n    \nclass SemSegModel(nn.Module):\n    def __init__(self, backbone, num_classes):\n        super(SemSegModel, self).__init__()\n        self.backbone = backbone\n        self.num_classes = num_classes\n        self.logits = BNReLUConv(backbone.num_features, self.num_classes)\n        self.multiscale_factors=(.5, .75, 1.5, 2.)\n        \n    def forward(self, image):\n        image_size = image.size()[2:4]\n        features, additional = self.backbone(image)\n        logits = self.logits.forward(features)\n        logits = upsample(logits, image_size)\n        additional['logits'] = logits\n        nonlin = nn.LogSoftmax(1)\n        return nonlin(logits)","metadata":{"papermill":{"duration":0.073801,"end_time":"2021-06-04T11:06:49.243247","exception":false,"start_time":"2021-06-04T11:06:49.169446","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-10T21:31:23.262769Z","iopub.execute_input":"2021-06-10T21:31:23.263088Z","iopub.status.idle":"2021-06-10T21:31:23.300786Z","shell.execute_reply.started":"2021-06-10T21:31:23.263055Z","shell.execute_reply":"2021-06-10T21:31:23.300023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pomoćne funkcije","metadata":{}},{"cell_type":"code","source":"def dice_score(prediction, ground_truth, smooth = 1.0):\n    prediction = prediction.contiguous().view(-1)\n    ground_truth = ground_truth.contiguous().view(-1)\n    \n    intersection = (prediction*ground_truth).sum()\n    score = (2*intersection+smooth)/(prediction.sum()+ground_truth.sum()+smooth)\n    return score\n\ndef un_one_hot(targets):\n    return targets.argmax(1)\n\ndef output_metrics(loss_avg, dice_scores, phase):\n    print(phase)\n    print(\"Average loss: {}\".format(loss_avg))\n    print(\"Dice score: {}\".format(dice_scores))\n\ndef dataset_evaluate(model, loader, loss_fn, threshold = -1, single = False):\n    global device\n    \n    loss_avg = 0.0\n    dice_scores = []\n    \n    with torch.no_grad():\n        model.eval()\n        for images, ground_truths in loader:\n            images = torch.cat([images[i] for i in range(b_s)])\n            ground_truths = torch.cat([ground_truths[i] for i in range(b_s)])\n            images = images.to(device)\n            ground_truths = ground_truths.to(device)\n            outputs = model(images)\n            loss = loss_fn(outputs, un_one_hot(ground_truths))\n            loss_avg += loss.item()\n            outputs = outputs.argmax(1)\n            ground_truths = ground_truths.argmax(1)\n            outputs_WT = outputs.clone()\n            outputs_WT[outputs_WT == 0] = 1\n            outputs_WT[outputs_WT == 1] = 1\n            outputs_WT[outputs_WT == 2] = 1\n            outputs_WT[outputs_WT == 3] = 0\n            outputs_TC = outputs.clone()\n            outputs_TC[outputs_TC == 0] = 0\n            outputs_TC[outputs_TC == 1] = 1\n            outputs_TC[outputs_TC == 2] = 1\n            outputs_TC[outputs_TC == 3] = 0\n            outputs_ET = outputs.clone()\n            outputs_ET[outputs_ET == 0] = 0\n            outputs_ET[outputs_ET == 1] = 0\n            outputs_ET[outputs_ET == 2] = 1\n            outputs_ET[outputs_ET == 3] = 0\n            ground_truths_WT = ground_truths.clone()\n            ground_truths_WT[ground_truths_WT == 0] = 1\n            ground_truths_WT[ground_truths_WT == 1] = 1\n            ground_truths_WT[ground_truths_WT == 2] = 1\n            ground_truths_WT[ground_truths_WT == 3] = 0\n            ground_truths_TC = ground_truths.clone()\n            ground_truths_TC[ground_truths_TC == 0] = 0\n            ground_truths_TC[ground_truths_TC == 1] = 1\n            ground_truths_TC[ground_truths_TC == 2] = 1\n            ground_truths_TC[ground_truths_TC == 3] = 0\n            ground_truths_ET = ground_truths.clone()\n            ground_truths_ET[ground_truths_ET == 0] = 0\n            ground_truths_ET[ground_truths_ET == 1] = 0\n            ground_truths_ET[ground_truths_ET == 2] = 1\n            ground_truths_ET[ground_truths_ET == 3] = 0\n            \n            dice_scores.append([dice_score(outputs_WT, ground_truths_WT),\n                                dice_score(outputs_TC, ground_truths_TC),\n                                dice_score(outputs_ET, ground_truths_ET)])\n                \n    loss_avg /= len(loader)\n    model.train()\n    dice_scores = np.stack(dice_scores)\n    return loss_avg, dice_scores.mean(0)","metadata":{"papermill":{"duration":0.048864,"end_time":"2021-06-04T11:06:49.37611","exception":false,"start_time":"2021-06-04T11:06:49.327246","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-10T21:31:23.302773Z","iopub.execute_input":"2021-06-10T21:31:23.303189Z","iopub.status.idle":"2021-06-10T21:31:23.321561Z","shell.execute_reply.started":"2021-06-10T21:31:23.303153Z","shell.execute_reply":"2021-06-10T21:31:23.320812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iscrtavanje grafa gubitka","metadata":{}},{"cell_type":"code","source":"def plot_progress(data):\n    valid_loss = data['valid loss']\n    train_loss = data['train loss']\n\n    fig, ax = plt.subplots(figsize=(16,8))\n    linewidth = 2\n    legend_size = 10\n    train_color = 'm'\n    val_color = 'c'\n\n    ax.set_title('Loss')\n    ax.plot(train_loss, marker='o', color=train_color,\n           linewidth=linewidth, linestyle='-', label='train')\n    ax.plot(valid_loss, marker='o', color=val_color,\n           linewidth=linewidth, linestyle='-', label='validation')\n    ax.legend(loc='upper right', fontsize=legend_size)\n\n    save_path = os.path.join('./', 'loss.png')\n    print('Plotting in: ', save_path)\n    plt.savefig(save_path)\n    return","metadata":{"papermill":{"duration":0.043246,"end_time":"2021-06-04T11:06:49.440365","exception":false,"start_time":"2021-06-04T11:06:49.397119","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-10T21:31:23.323094Z","iopub.execute_input":"2021-06-10T21:31:23.323501Z","iopub.status.idle":"2021-06-10T21:31:23.332643Z","shell.execute_reply.started":"2021-06-10T21:31:23.323464Z","shell.execute_reply":"2021-06-10T21:31:23.33195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Treniranje i evaluacija modela","metadata":{}},{"cell_type":"code","source":"def train_network():\n    global device\n    plot_data = {}\n    plot_data[\"train loss\"] = []\n    plot_data[\"valid loss\"] = []\n    plot_data[\"WT valid dice\"] = []\n    plot_data[\"TC valid dice\"] = []\n    plot_data[\"ET valid dice\"] = []\n    plot_data[\"test loss\"] = 0\n    plot_data[\"WT test dice\"] = []\n    plot_data[\"TC test dice\"] = []\n    plot_data[\"ET test dice\"] = []\n    plot_data[\"lr\"] = []\n    \n    SAVE_PATH = \"./network.pt\"\n    print(\"device:\", device)\n    \n    resnet18 = models.resnet18(pretrained=True)\n    myresnet = ResNet(BasicBlock, [2,2,2,2])\n\n    pretrained_dict = resnet18.state_dict()\n    model_dict = myresnet.state_dict()\n\n    conv_weight = pretrained_dict.pop('conv1.weight')\n    mean_kernel = conv_weight.mean(dim=1)\n    mean_kernel = torch.unsqueeze(mean_kernel, dim=1)\n    mean_kernel = torch.cat([mean_kernel]*4, dim = 1)\n    pretrained_dict['conv1.weight'] = mean_kernel\n\n    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n    pretrained_names = list(pretrained_dict.keys())\n    model_dict.update(pretrained_dict)\n\n    myresnet.load_state_dict(model_dict)\n    \n    net = SemSegModel(myresnet, 4).to(device = device)\n    lossFunc = nn.NLLLoss(weight = torch.tensor([2,5,3,1]).float().to(device))\n    \n    base_params = [v[1] for v in list(filter(lambda kv: kv[0] not in pretrained_names, net.named_parameters()))]\n    pretrained_params = [v[1] for v in list(filter(lambda kv: kv[0] in pretrained_names, net.named_parameters()))]\n    \n    optimizer = optim.Adam([{'params': base_params}, {'params': pretrained_params, 'lr':learning_rate/scaling_factor}], lr=learning_rate, weight_decay = weight_decay)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = num_epochs, eta_min = 1e-6)\n    \n    for e in range(num_epochs):\n        accLoss = 0.\n        net.train()\n        i = -1\n        for inputs, ground_truths in trainloader:\n            i+=1\n            inputs = torch.cat([inputs[i] for i in range(b_s)])\n            ground_truths = torch.cat([ground_truths[i] for i in range(b_s)])\n            inputs.requires_grad = True\n            inputs = inputs.to(device)\n            ground_truths = ground_truths.to(device)\n            \n            outputs = net(inputs)\n            loss = lossFunc(outputs, un_one_hot(ground_truths))\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            accLoss += loss.item()\n\n            if i % 10 == 0:\n                print(\"Epoch: %d, Iteration: %5d, Loss: %.3f\" % ((e + 1), (i+1), (accLoss / (i + 1))))\n        trainset.reset()\n\n        val_loss, val_dice = dataset_evaluate(net, validloader, lossFunc)\n        validset.reset()\n        output_metrics(val_loss, val_dice, \"Validation\")\n        plot_data[\"valid loss\"].append(val_loss)\n        plot_data[\"WT valid dice\"].append(val_dice[0])\n        plot_data[\"TC valid dice\"].append(val_dice[1])\n        plot_data[\"ET valid dice\"].append(val_dice[2])\n        \n        plot_data[\"lr\"].append(scheduler.get_last_lr())\n        plot_data[\"train loss\"].append(accLoss/(i+1))\n        \n        scheduler.step()\n    \n    test_loss, test_dice = dataset_evaluate(net, testloader, lossFunc)\n    output_metrics(test_loss, test_dice, \"Test:\")\n    \n    plot_data[\"test loss\"] = test_loss\n    plot_data[\"WT test dice\"] = test_dice[0]\n    plot_data[\"TC test dice\"] = test_dice[1]\n    plot_data[\"ET test dice\"] = test_dice[2]\n    \n    torch.save(net.state_dict(), SAVE_PATH)\n    \n    with open(\"./epoch_data.txt\", 'w') as f:\n        f.write(repr(plot_data))\n\n    plot_progress(plot_data)\n\n    return plot_data\n    \n    \nepoch_data = train_network()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T21:31:23.333992Z","iopub.execute_input":"2021-06-10T21:31:23.334494Z","iopub.status.idle":"2021-06-10T21:50:16.312168Z","shell.execute_reply.started":"2021-06-10T21:31:23.334459Z","shell.execute_reply":"2021-06-10T21:50:16.310129Z"},"trusted":true},"execution_count":null,"outputs":[]}]}